{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-go GOAL] [-dev {cpu,cuda}]\n",
      "                             [-did DEVICE_ID] [-data DATASET]\n",
      "                             [-nb NUM_CLASSES] [-m MODEL] [-p HEAD]\n",
      "                             [-lbs BATCH_SIZE] [-lr LOCAL_LEARNING_RATE]\n",
      "                             [-gr GLOBAL_ROUNDS] [-ls LOCAL_STEPS]\n",
      "                             [-algo ALGORITHM] [-jr JOIN_RATIO]\n",
      "                             [-rjr RANDOM_JOIN_RATIO] [-nc NUM_CLIENTS]\n",
      "                             [-pv PREV] [-t TIMES] [-eg EVAL_GAP]\n",
      "                             [-dp PRIVACY] [-dps DP_SIGMA]\n",
      "                             [-sfn SAVE_FOLDER_NAME] [-cdr CLIENT_DROP_RATE]\n",
      "                             [-tsr TRAIN_SLOW_RATE] [-ssr SEND_SLOW_RATE]\n",
      "                             [-ts TIME_SELECT] [-tth TIME_THRETHOLD]\n",
      "                             [-bt BETA] [-lam LAMDA] [-mu MU] [-K K]\n",
      "                             [-lrp P_LEARNING_RATE] [-M M] [-itk ITK]\n",
      "                             [-alk ALPHAK] [-sg SIGMA] [-al ALPHA]\n",
      "                             [-pls PLOCAL_STEPS] [-ta TAU]\n",
      "                             [-fts FINE_TUNING_STEPS] [-dlr DR_LEARNING_RATE]\n",
      "                             [-L L] [-ere EVERY_RECLUSTER_EPS] [-ed EMB_DIM]\n",
      "                             [-alr ATTN_LEARNING_RATE] [-ncl NUM_CLUSTER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: - d a t a   m n i s t   - m   c n n   - a l g o   F e d T r a n s   - g r   2 5 0 0   - d i d   0   - g o   c n n   - n c   2\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!/usr/bin/env python\n",
    "import copy\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import logging\n",
    "\n",
    "from flcore.servers.serveravg import FedAvg\n",
    "from flcore.servers.serverpFedMe import pFedMe\n",
    "from flcore.servers.serverperavg import PerAvg\n",
    "from flcore.servers.serverprox import FedProx\n",
    "from flcore.servers.serverfomo import FedFomo\n",
    "from flcore.servers.serveramp import FedAMP\n",
    "from flcore.servers.servermtl import FedMTL\n",
    "from flcore.servers.serverlocal import Local\n",
    "from flcore.servers.serverper import FedPer\n",
    "from flcore.servers.serverapfl import APFL\n",
    "from flcore.servers.serverditto import Ditto\n",
    "from flcore.servers.serverrep import FedRep\n",
    "from flcore.servers.serverphp import FedPHP\n",
    "from flcore.servers.serverbn import FedBN\n",
    "from flcore.servers.serverrod import FedROD\n",
    "from flcore.servers.serverproto import FedProto\n",
    "from flcore.servers.serverdyn import FedDyn\n",
    "from flcore.servers.servermoon import MOON\n",
    "from flcore.servers.serverbabu import FedBABU\n",
    "from flcore.servers.serverapple import APPLE\n",
    "from flcore.servers.serverfedtrans import FedTrans \n",
    "\n",
    "from flcore.trainmodel.models import *\n",
    "\n",
    "from flcore.trainmodel.bilstm import BiLSTM_TextClassification\n",
    "# from flcore.trainmodel.resnet import resnet18 as resnet\n",
    "from flcore.trainmodel.alexnet import alexnet\n",
    "from flcore.trainmodel.mobilenet_v2 import mobilenet_v2\n",
    "from utils.result_utils import average_data\n",
    "from utils.mem_utils import MemReporter\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# hyper-params for Text tasks\n",
    "vocab_size = 98635\n",
    "max_len=200\n",
    "hidden_dim=32\n",
    "\n",
    "def run(args):\n",
    "\n",
    "    time_list = []\n",
    "    reporter = MemReporter()\n",
    "    model_str = args.model\n",
    "\n",
    "    for i in range(args.prev, args.times):\n",
    "        print(f\"\\n============= Running time: {i}th =============\")\n",
    "        print(\"Creating server and clients ...\")\n",
    "        start = time.time()\n",
    "\n",
    "        # Generate args.model\n",
    "        if model_str == \"mlr\":\n",
    "            if args.dataset == \"mnist\" or args.dataset == \"fmnist\":\n",
    "                args.model = Mclr_Logistic(1*28*28, num_classes=args.num_classes).to(args.device)\n",
    "            elif args.dataset == \"Cifar10\" or args.dataset == \"Cifar100\":\n",
    "                args.model = Mclr_Logistic(3*32*32, num_classes=args.num_classes).to(args.device)\n",
    "            else:\n",
    "                args.model = Mclr_Logistic(60, num_classes=args.num_classes).to(args.device)\n",
    "\n",
    "        elif model_str == \"cnn\":\n",
    "            if args.dataset[:5] == \"mnist\" or args.dataset == \"fmnist\":\n",
    "                args.model = FedAvgCNN(in_features=1, num_classes=args.num_classes, dim=1024).to(args.device)\n",
    "            elif args.dataset == \"omniglot\":\n",
    "                args.model = FedAvgCNN(in_features=1, num_classes=args.num_classes, dim=33856).to(args.device)\n",
    "            elif args.dataset[:5] == \"Cifar\":\n",
    "                args.model = FedAvgCNN(in_features=3, num_classes=args.num_classes, dim=1600).to(args.device)\n",
    "                # args.model = CifarNet(num_classes=args.num_classes).to(args.device)\n",
    "            elif args.dataset == \"Digit5\":\n",
    "                args.model = Digit5CNN().to(args.device)\n",
    "            else:\n",
    "                args.model = FedAvgCNN(in_features=3, num_classes=args.num_classes, dim=10816).to(args.device)\n",
    "\n",
    "        elif model_str == \"dnn\": # non-convex\n",
    "            if args.dataset == \"mnist\" or args.dataset == \"fmnist\":\n",
    "                args.model = DNN(1*28*28, 100, num_classes=args.num_classes).to(args.device)\n",
    "            elif args.dataset == \"Cifar10\" or args.dataset == \"Cifar100\":\n",
    "                args.model = DNN(3*32*32, 100, num_classes=args.num_classes).to(args.device)\n",
    "            else:\n",
    "                args.model = DNN(60, 20, num_classes=args.num_classes).to(args.device)\n",
    "        \n",
    "        elif model_str == \"resnet\":\n",
    "            args.model = torchvision.models.resnet18(pretrained=False, num_classes=args.num_classes).to(args.device)\n",
    "            \n",
    "            # args.model = torchvision.models.resnet18(pretrained=True).to(args.device)\n",
    "            # feature_dim = list(args.model.fc.parameters())[0].shape[1]\n",
    "            # args.model.fc = nn.Linear(feature_dim, args.num_classes).to(args.device)\n",
    "            \n",
    "            # args.model = resnet18(num_classes=args.num_classes, has_bn=True, bn_block_num=4).to(args.device)\n",
    "\n",
    "        elif model_str == \"alexnet\":\n",
    "            args.model = alexnet(pretrained=False, num_classes=args.num_classes).to(args.device)\n",
    "            \n",
    "            # args.model = alexnet(pretrained=True).to(args.device)\n",
    "            # feature_dim = list(args.model.fc.parameters())[0].shape[1]\n",
    "            # args.model.fc = nn.Linear(feature_dim, args.num_classes).to(args.device)\n",
    "            \n",
    "        elif model_str == \"googlenet\":\n",
    "            args.model = torchvision.models.googlenet(pretrained=False, aux_logits=False, num_classes=args.num_classes).to(args.device)\n",
    "            \n",
    "            # args.model = torchvision.models.googlenet(pretrained=True, aux_logits=False).to(args.device)\n",
    "            # feature_dim = list(args.model.fc.parameters())[0].shape[1]\n",
    "            # args.model.fc = nn.Linear(feature_dim, args.num_classes).to(args.device)\n",
    "\n",
    "        elif model_str == \"mobilenet_v2\":\n",
    "            args.model = mobilenet_v2(pretrained=False, num_classes=args.num_classes).to(args.device)\n",
    "            \n",
    "            # args.model = mobilenet_v2(pretrained=True).to(args.device)\n",
    "            # feature_dim = list(args.model.fc.parameters())[0].shape[1]\n",
    "            # args.model.fc = nn.Linear(feature_dim, args.num_classes).to(args.device)\n",
    "            \n",
    "        elif model_str == \"lstm\":\n",
    "            args.model = LSTMNet(hidden_dim=hidden_dim, vocab_size=vocab_size, num_classes=args.num_classes).to(args.device)\n",
    "\n",
    "        elif model_str == \"bilstm\":\n",
    "            args.model = BiLSTM_TextClassification(input_size=vocab_size, hidden_size=hidden_dim, output_size=args.num_classes, \n",
    "                        num_layers=1, embedding_dropout=0, lstm_dropout=0, attention_dropout=0, \n",
    "                        embedding_length=hidden_dim).to(args.device)\n",
    "\n",
    "        elif model_str == \"fastText\":\n",
    "            args.model = fastText(hidden_dim=hidden_dim, vocab_size=vocab_size, num_classes=args.num_classes).to(args.device)\n",
    "\n",
    "        elif model_str == \"TextCNN\":\n",
    "            args.model = TextCNN(hidden_dim=hidden_dim, max_len=max_len, vocab_size=vocab_size, \n",
    "                            num_classes=args.num_classes).to(args.device)\n",
    "\n",
    "        elif model_str == \"Transformer\":\n",
    "            args.model = TransformerModel(ntoken=vocab_size, d_model=hidden_dim, nhead=2, d_hid=hidden_dim, nlayers=2, \n",
    "                            num_classes=args.num_classes).to(args.device)\n",
    "        \n",
    "        elif model_str == \"AmazonMLP\":\n",
    "            args.model = AmazonMLP().to(args.device)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        print(args.model)\n",
    "\n",
    "        # select algorithm\n",
    "        if args.algorithm == \"FedAvg\":\n",
    "            server = FedAvg(args, i)\n",
    "\n",
    "        elif args.algorithm == \"Local\":\n",
    "            server = Local(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedMTL\":\n",
    "            server = FedMTL(args, i)\n",
    "\n",
    "        elif args.algorithm == \"PerAvg\":\n",
    "            server = PerAvg(args, i)\n",
    "\n",
    "        elif args.algorithm == \"pFedMe\":\n",
    "            server = pFedMe(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedProx\":\n",
    "            server = FedProx(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedFomo\":\n",
    "            server = FedFomo(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedAMP\":\n",
    "            server = FedAMP(args, i)\n",
    "\n",
    "        elif args.algorithm == \"APFL\":\n",
    "            server = APFL(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedPer\":\n",
    "            args.head = copy.deepcopy(args.model.fc)\n",
    "            args.model.fc = nn.Identity()\n",
    "            args.model = LocalModel(args.model, args.head)\n",
    "            server = FedPer(args, i)\n",
    "\n",
    "        elif args.algorithm == \"Ditto\":\n",
    "            server = Ditto(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedRep\":\n",
    "            args.head = copy.deepcopy(args.model.fc)\n",
    "            args.model.fc = nn.Identity()\n",
    "            args.model = LocalModel(args.model, args.head)\n",
    "            server = FedRep(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedPHP\":\n",
    "            args.head = copy.deepcopy(args.model.fc)\n",
    "            args.model.fc = nn.Identity()\n",
    "            args.model = LocalModel(args.model, args.head)\n",
    "            server = FedPHP(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedBN\":\n",
    "            server = FedBN(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedROD\":\n",
    "            args.head = copy.deepcopy(args.model.fc)\n",
    "            args.model.fc = nn.Identity()\n",
    "            args.model = LocalModel(args.model, args.head)\n",
    "            server = FedROD(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedProto\":\n",
    "            args.head = copy.deepcopy(args.model.fc)\n",
    "            args.model.fc = nn.Identity()\n",
    "            args.model = LocalModel(args.model, args.head)\n",
    "            server = FedProto(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedDyn\":\n",
    "            server = FedDyn(args, i)\n",
    "\n",
    "        elif args.algorithm == \"MOON\":\n",
    "            args.head = copy.deepcopy(args.model.fc)\n",
    "            args.model.fc = nn.Identity()\n",
    "            args.model = LocalModel(args.model, args.head)\n",
    "            server = MOON(args, i)\n",
    "\n",
    "        elif args.algorithm == \"FedBABU\":\n",
    "            args.head = copy.deepcopy(args.model.fc)\n",
    "            args.model.fc = nn.Identity()\n",
    "            args.model = LocalModel(args.model, args.head)\n",
    "            server = FedBABU(args, i)\n",
    "\n",
    "        elif args.algorithm == \"APPLE\":\n",
    "            server = APPLE(args, i)\n",
    "            \n",
    "        elif args.algorithm == \"FedTrans\":\n",
    "            args.head = copy.deepcopy(args.model.fc)\n",
    "            args.model.fc = nn.Identity()\n",
    "            args.model = LocalModel(args.model, args.head)\n",
    "            server = FedTrans(args, i)\n",
    "            \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    return server\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total_start = time.time()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # general\n",
    "    parser.add_argument('-go', \"--goal\", type=str, default=\"test\", \n",
    "                        help=\"The goal for this experiment\")\n",
    "    parser.add_argument('-dev', \"--device\", type=str, default=\"cuda\",\n",
    "                        choices=[\"cpu\", \"cuda\"])\n",
    "    parser.add_argument('-did', \"--device_id\", type=str, default=\"0\")\n",
    "    parser.add_argument('-data', \"--dataset\", type=str, default=\"mnist\")\n",
    "    parser.add_argument('-nb', \"--num_classes\", type=int, default=10)\n",
    "    parser.add_argument('-m', \"--model\", type=str, default=\"cnn\")\n",
    "    parser.add_argument('-p', \"--head\", type=str, default=\"cnn\")\n",
    "    parser.add_argument('-lbs', \"--batch_size\", type=int, default=10)\n",
    "    parser.add_argument('-lr', \"--local_learning_rate\", type=float, default=0.005,\n",
    "                        help=\"Local learning rate\")\n",
    "    parser.add_argument('-gr', \"--global_rounds\", type=int, default=1000)\n",
    "    parser.add_argument('-ls', \"--local_steps\", type=int, default=1)\n",
    "    parser.add_argument('-algo', \"--algorithm\", type=str, default=\"FedAvg\")\n",
    "    parser.add_argument('-jr', \"--join_ratio\", type=float, default=1.0,\n",
    "                        help=\"Ratio of clients per round\")\n",
    "    parser.add_argument('-rjr', \"--random_join_ratio\", type=bool, default=False,\n",
    "                        help=\"Random ratio of clients per round\")\n",
    "    parser.add_argument('-nc', \"--num_clients\", type=int, default=2,\n",
    "                        help=\"Total number of clients\")\n",
    "    parser.add_argument('-pv', \"--prev\", type=int, default=0,\n",
    "                        help=\"Previous Running times\")\n",
    "    parser.add_argument('-t', \"--times\", type=int, default=1,\n",
    "                        help=\"Running times\")\n",
    "    parser.add_argument('-eg', \"--eval_gap\", type=int, default=1,\n",
    "                        help=\"Rounds gap for evaluation\")\n",
    "    parser.add_argument('-dp', \"--privacy\", type=bool, default=False,\n",
    "                        help=\"differential privacy\")\n",
    "    parser.add_argument('-dps', \"--dp_sigma\", type=float, default=0.0)\n",
    "    parser.add_argument('-sfn', \"--save_folder_name\", type=str, default='models')\n",
    "    # practical\n",
    "    parser.add_argument('-cdr', \"--client_drop_rate\", type=float, default=0.0,\n",
    "                        help=\"Rate for clients that train but drop out\")\n",
    "    parser.add_argument('-tsr', \"--train_slow_rate\", type=float, default=0.0,\n",
    "                        help=\"The rate for slow clients when training locally\")\n",
    "    parser.add_argument('-ssr', \"--send_slow_rate\", type=float, default=0.0,\n",
    "                        help=\"The rate for slow clients when sending global model\")\n",
    "    parser.add_argument('-ts', \"--time_select\", type=bool, default=False,\n",
    "                        help=\"Whether to group and select clients at each round according to time cost\")\n",
    "    parser.add_argument('-tth', \"--time_threthold\", type=float, default=10000,\n",
    "                        help=\"The threthold for droping slow clients\")\n",
    "    # pFedMe / PerAvg / FedProx / FedAMP / FedPHP\n",
    "    parser.add_argument('-bt', \"--beta\", type=float, default=0.0,\n",
    "                        help=\"Average moving parameter for pFedMe, Second learning rate of Per-FedAvg, \\\n",
    "                        or L1 regularization weight of FedTransfer\")\n",
    "    parser.add_argument('-lam', \"--lamda\", type=float, default=1.0,\n",
    "                        help=\"Regularization weight for pFedMe and FedAMP\")\n",
    "    parser.add_argument('-mu', \"--mu\", type=float, default=0,\n",
    "                        help=\"Proximal rate for FedProx\")\n",
    "    parser.add_argument('-K', \"--K\", type=int, default=5,\n",
    "                        help=\"Number of personalized training steps for pFedMe\")\n",
    "    parser.add_argument('-lrp', \"--p_learning_rate\", type=float, default=0.01,\n",
    "                        help=\"personalized learning rate to caculate theta aproximately using K steps\")\n",
    "    # FedFomo\n",
    "    parser.add_argument('-M', \"--M\", type=int, default=5,\n",
    "                        help=\"Server only sends M client models to one client at each round\")\n",
    "    # FedMTL\n",
    "    parser.add_argument('-itk', \"--itk\", type=int, default=4000,\n",
    "                        help=\"The iterations for solving quadratic subproblems\")\n",
    "    # FedAMP\n",
    "    parser.add_argument('-alk', \"--alphaK\", type=float, default=1.0, \n",
    "                        help=\"lambda/sqrt(GLOABL-ITRATION) according to the paper\")\n",
    "    parser.add_argument('-sg', \"--sigma\", type=float, default=1.0)\n",
    "    # APFL\n",
    "    parser.add_argument('-al', \"--alpha\", type=float, default=1.0)\n",
    "    # Ditto / FedRep\n",
    "    parser.add_argument('-pls', \"--plocal_steps\", type=int, default=1)\n",
    "    # MOON\n",
    "    parser.add_argument('-ta', \"--tau\", type=float, default=1.0)\n",
    "    # FedBABU\n",
    "    parser.add_argument('-fts', \"--fine_tuning_steps\", type=int, default=1)\n",
    "    # APPLE\n",
    "    parser.add_argument('-dlr', \"--dr_learning_rate\", type=float, default=0.0)\n",
    "    parser.add_argument('-L', \"--L\", type=float, default=1.0)\n",
    "    #FedTrans\n",
    "    parser.add_argument('-ere', \"--every_recluster_eps\", type=int, default=5)\n",
    "    parser.add_argument('-ed', \"--emb_dim\", type=int, default=128)\n",
    "    parser.add_argument('-alr', \"--attn_learning_rate\", type=float, default=0.005)\n",
    "    parser.add_argument('-ncl', \"--num_cluster\", type=int, default=10)\n",
    "\n",
    "    \n",
    "    args = parser.parse_args(args=[\"-data\",\"mnist\", \"-m\", \"cnn\", -algo FedTrans -gr 2500 -did 0 -go cnn -nc 2\")\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.device_id\n",
    "\n",
    "    if args.device == \"cuda\" and not torch.cuda.is_available():\n",
    "        print(\"\\ncuda is not avaiable.\\n\")\n",
    "        args.device = \"cpu\"\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    print(\"Algorithm: {}\".format(args.algorithm))\n",
    "    print(\"Local batch size: {}\".format(args.batch_size))\n",
    "    print(\"Local steps: {}\".format(args.local_steps))\n",
    "    print(\"Local learing rate: {}\".format(args.local_learning_rate))\n",
    "    print(\"Total number of clients: {}\".format(args.num_clients))\n",
    "    print(\"Clients join in each round: {}\".format(args.join_ratio))\n",
    "    print(\"Client drop rate: {}\".format(args.client_drop_rate))\n",
    "    print(\"Time select: {}\".format(args.time_select))\n",
    "    print(\"Time threthold: {}\".format(args.time_threthold))\n",
    "    print(\"Global rounds: {}\".format(args.global_rounds))\n",
    "    print(\"Running times: {}\".format(args.times))\n",
    "    print(\"Dataset: {}\".format(args.dataset))\n",
    "    print(\"Local model: {}\".format(args.model))\n",
    "    print(\"Using device: {}\".format(args.device))\n",
    "\n",
    "    if args.device == \"cuda\":\n",
    "        print(\"Cuda device id: {}\".format(os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "\n",
    "    # if args.dataset == \"mnist\" or args.dataset == \"fmnist\":\n",
    "    #     generate_mnist('../dataset/mnist/', args.num_clients, 10, args.niid)\n",
    "    # elif args.dataset == \"Cifar10\" or args.dataset == \"Cifar100\":\n",
    "    #     generate_cifar10('../dataset/Cifar10/', args.num_clients, 10, args.niid)\n",
    "    # else:\n",
    "    #     generate_synthetic('../dataset/synthetic/', args.num_clients, 10, args.niid)\n",
    "\n",
    "    # with torch.profiler.profile(\n",
    "    #     activities=[\n",
    "    #         torch.profiler.ProfilerActivity.CPU,\n",
    "    #         torch.profiler.ProfilerActivity.CUDA],\n",
    "    #     profile_memory=True, \n",
    "    #     on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')\n",
    "    #     ) as prof:\n",
    "    # with torch.autograd.profiler.profile(profile_memory=True) as prof:\n",
    "    server = run(args)\n",
    "\n",
    "    \n",
    "    # print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20))\n",
    "    # print(f\"\\nTotal time cost: {round(time.time()-total_start, 2)}s.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beb37d7b78bf3788f54259aa41c6c1e59fac34bf95ae5ff22b978ccc20cf7a1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
